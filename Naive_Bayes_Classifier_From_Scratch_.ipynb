{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In classification, the goal of a learning\n",
        "algorithm is to construct a classifier given a set of training examples with class labels. Naive Bayes is a simple and effective probabilistic classifier based on applying Baye's theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable.\n",
        "\n",
        "Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.\n",
        "\n",
        "Bayes Theorem provides a principled way for calculating a conditional probability.\n",
        "\n",
        "P(class|data) = (P(data|class) * P(class)) / P(data)\n",
        "\n",
        "Where P(class|data) is the probability of class given the provided data.\n",
        "\n",
        "In this code, a Naive Bayes Classifier will be developed following the next steps:\n",
        "\n",
        "1- Divide data into clases.\n",
        "\n",
        "2- Get Mean and Standar desviation\n",
        "\n",
        "3- Obtain Gaussian Probability Density Function\n",
        "\n",
        "4- Make predictions\n",
        "\n",
        "5- Evaluate model performance\n",
        "\n",
        "Finally, the model is encapsulated within a class and its accuracy is compared to that obtained using the 'sklearn' library.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The data set used is \"Pima Indians Diabetes Database\" from the National Institute of Diabetes and Digestive and Kidney Diseases.\n",
        "\n",
        "The variables are:\n",
        "\n",
        "Pregnancies: Number of pregnancies the patient has had.\n",
        "\n",
        "Plasma Glucose (mg/dl): Plasma glucose concentration.\n",
        "\n",
        "Blood Pressure (mm Hg): Diastolic blood pressure in mm Hg.\n",
        "\n",
        "Triceps Skin Fold Thickness (mm): Triceps skin fold thickness in mm.\n",
        "\n",
        "2-Hour Post-Prandial Blood Sugar(mg/dl): Blood sugar level 2 hours after a meal.\n",
        "\n",
        "Body Mass Index (BMI)\n",
        "\n",
        "Insulin Level (mu U/ml): Insulin concentration in micro units per milliliter.\n",
        "\n",
        "Age (years): Age of the patient in years.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
        "\n",
        "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        "\n",
        "Data set:\n",
        "\n",
        "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n"
      ],
      "metadata": {
        "id": "lWVIzNOsbhcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries."
      ],
      "metadata": {
        "id": "Fi4VuXmlg7X5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DcXWxoJll6kI"
      },
      "outputs": [],
      "source": [
        "import pandas as  pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Google Drive could be not necessary if the code is run on a platform other than Google Colab."
      ],
      "metadata": {
        "id": "7gsS4OS7hGF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22EWrazqz7c",
        "outputId": "2862ac71-246f-4421-a042-863bc6c82b86"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "jZiWhbL3hxJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the path to your CSV file\n",
        "csv_path = '/content/drive/MyDrive/Colab Notebooks/primerose codes/data sets/diabetes.csv'\n",
        "\n",
        "# Read CSV file into a DataFrame\n",
        "data = pd.read_csv(csv_path).values"
      ],
      "metadata": {
        "id": "havIwSOQtykj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check data head"
      ],
      "metadata": {
        "id": "tFthhfyQfExr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr1wCTYTUVzz",
        "outputId": "48f57478-67bc-4b50-90f0-9863119e1d74"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
              "        6.270e-01, 5.000e+01, 1.000e+00],\n",
              "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
              "        3.510e-01, 3.100e+01, 0.000e+00],\n",
              "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
              "        6.720e-01, 3.200e+01, 1.000e+00],\n",
              "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
              "        1.670e-01, 2.100e+01, 0.000e+00],\n",
              "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
              "        2.288e+00, 3.300e+01, 1.000e+00],\n",
              "       [5.000e+00, 1.160e+02, 7.400e+01, 0.000e+00, 0.000e+00, 2.560e+01,\n",
              "        2.010e-01, 3.000e+01, 0.000e+00],\n",
              "       [3.000e+00, 7.800e+01, 5.000e+01, 3.200e+01, 8.800e+01, 3.100e+01,\n",
              "        2.480e-01, 2.600e+01, 1.000e+00],\n",
              "       [1.000e+01, 1.150e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.530e+01,\n",
              "        1.340e-01, 2.900e+01, 0.000e+00],\n",
              "       [2.000e+00, 1.970e+02, 7.000e+01, 4.500e+01, 5.430e+02, 3.050e+01,\n",
              "        1.580e-01, 5.300e+01, 1.000e+00],\n",
              "       [8.000e+00, 1.250e+02, 9.600e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        2.320e-01, 5.400e+01, 1.000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split arrays into random train and test subsets."
      ],
      "metadata": {
        "id": "e8iZkeGqh-5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "x = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y)\n"
      ],
      "metadata": {
        "id": "z_lZ2KuFuCj-"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print()\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfN3Hgs0uXev",
        "outputId": "14775319-a2f2-4523-dfb3-e9e5327f52a6"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 8)\n",
            "\n",
            "(768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Separate by class:\n",
        "\n",
        "Separating by class involves categorizing data based on target labels. In this particular scenario, we have two target labels: 0 and 1.\n",
        "We compute the mean and standard deviation for each feature (column) within each label.\n",
        "\n"
      ],
      "metadata": {
        "id": "LJP4QTxaFBOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_and_std_per_label(x,y,wanted_label):\n",
        "    #select the valuesof each class\n",
        "    x_with_specific_class = x[y==wanted_label]\n",
        "    #calculates media and. standar desviation\n",
        "    mean = np.mean(x_with_specific_class,axis=0)\n",
        "    std = np.std(x_with_specific_class,axis=0)\n",
        "    return mean,std"
      ],
      "metadata": {
        "id": "2BDPIle4D9hJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Mean and Standar desviation:\n",
        "\n",
        "Obtain the mean and standard deviation for each feature (column) within each class."
      ],
      "metadata": {
        "id": "y8dEFVyhLB2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mean_std(x,y):\n",
        "    #calculates mean and std for each wanted label, 0 or 1 for this excercise\n",
        "    mean_label_0,std_label_0 = mean_and_std_per_label(x,y,0)\n",
        "    mean_label_1,std_label_1 = mean_and_std_per_label(x,y,1)\n",
        "    return mean_label_0,std_label_0,mean_label_1,std_label_1"
      ],
      "metadata": {
        "id": "U5E14LH5G5s1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- Gaussian Probability Density Function:\n",
        "\n",
        "A Gaussian distribution can be characterized by two parameters: the mean and the standard deviation. Consequently, using these statistical measures, we can approximate the likelihood of observing a particular value. This calculation is encapsulated within a Gaussian Probability Distribution Function (or Gaussian PDF), which can be expressed as:\n",
        "f(x) = (1 / sqrt(2 * PI) * sigma) * exp(-((x-mean)^2 / (2 * sigma^2)))\n",
        "\n",
        "\n",
        "The function calculates the probability of observing a specific value or set of values x in a Gaussian (normal) distribution.\n",
        "We get 8 probabilities (one for each feature) as result"
      ],
      "metadata": {
        "id": "EG1mts4UVEdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_gussian(x,mean,std):\n",
        "    # This line calculates the probability density function (PDF) of the observed value(s) x for each dimension\n",
        "    # of the Gaussian distribution.  we could also calculate it using the library scipy prob_array = scipy.stats.norm.pdf( x[i], mean[i], std[i])\n",
        "    prob_array = (1/(np.sqrt(2*math.pi)*std))*np.exp(-(x-mean)**2/(2*std**2))\n",
        "\n",
        "    #This line reshapes the prob_array to ensure it's represented as a column vector.\n",
        "    prob_array = np.reshape(prob_array, (prob_array.shape[0],1))\n",
        "\n",
        "    #the function computes the product of elements along the rows. Naive asumption, each row is independent\n",
        "    prob = np.prod(prob_array,axis=0)\n",
        "    return prob"
      ],
      "metadata": {
        "id": "-MrGQja3M4T8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4- Predictions:\n",
        "\n",
        "Now it's time to utilize the statistical parameters derived from our training dataset to compute probabilities for new data.\n",
        "\n",
        "Probabilities are computed independently for each class. This implies that initially, we compute the probability of a new data point belonging to the first class, followed by calculating probabilities for it belonging to the second class.\n",
        "\n",
        "The likelihood that a piece of data belongs to a particular class is calculated using the formula:\n",
        "\n",
        "P(class|data) = P(X|class) * P(class)\n",
        "\n",
        "Note that the denominator has been removed to simplify the calculation. This adjustment means that the resulting value is no longer strictly a probability of the data belonging to a class. However, the value is still maximized, implying that the calculation determines the class prediction based on the largest resulting value.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fr2p75G79QOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_dataset(x_values,mean_label_0,std_label_0,mean_label_1,std_label_1):\n",
        "    prob0 = []\n",
        "    prob1 = []\n",
        "    for row in x_values:\n",
        "        #calculates gaussian prob for each class\n",
        "        prob0_row = predict_gussian(row,mean_label_0,std_label_0)\n",
        "        prob1_row = predict_gussian(row,mean_label_1,std_label_1)\n",
        "        #attach it as list\n",
        "        prob0.append(prob0_row)\n",
        "        prob1.append(prob1_row)\n",
        "    #creates two columns with probabilities\n",
        "    probabilities = np.column_stack( (prob0,prob1))\n",
        "\n",
        "    # make the prediction based on the bigger value\n",
        "    y_calculated = np.argmax(probabilities,axis=1)\n",
        "    return y_calculated"
      ],
      "metadata": {
        "id": "m_ahbZD7XUJf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5- Accuracy:\n",
        "\n",
        "To evaluate the model's predictive performance, this function compares the predictions against the true labels. It returns the calculated accuracy score, representing the proportion of correctly predicted outcomes in the test dataset."
      ],
      "metadata": {
        "id": "faPS0By4_eUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(x_test,y_test,mean0,std0,mean1,std1):\n",
        "    y_calculated = predict_on_dataset(x_test,mean0,std0,mean1,std1)\n",
        "    diff = y_calculated - y_test #si es correcto da 0, incorrecto +- 1\n",
        "    wrong_points = np.sum(np.sqrt(diff**2) ) #eleva al cuadrado por los negativos, saca raiz\n",
        "    length = y_calculated.shape[0]\n",
        "    accuracy = 1-wrong_points/length\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "N986d_qmASTZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the Naive Bayes Classifier is built, let's encapsulate its functionality within a class using object-oriented programming principles."
      ],
      "metadata": {
        "id": "BcTkvx3VBfYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.alg_name = 'NaiveBayes'\n",
        "        self.mean0 = ''\n",
        "        self.std0 = ''\n",
        "        self.mean1 = ''\n",
        "        self.std1 = ''\n",
        "\n",
        "    def fit(self,x_train,y_train):\n",
        "        mean0,std0,mean1,std1 = calc_mean_std(x_train,y_train)\n",
        "        self.mean0 = mean0\n",
        "        self.mean1 = mean1\n",
        "        self.std0 = std0\n",
        "        self.std1 = std1\n",
        "\n",
        "    def predict(self,x_test):\n",
        "        prob0 = []\n",
        "        prob1 = []\n",
        "        for row in x_test:\n",
        "            prob0_row = predict_gussian(row,self.mean0,self.std0)\n",
        "            prob1_row = predict_gussian(row,self.mean1,self.std1)\n",
        "            prob0.append(prob0_row)\n",
        "            prob1.append(prob1_row)\n",
        "        probabilities = np.column_stack( (prob0,prob1))\n",
        "        y_calculated = np.argmax(probabilities)\n",
        "        return y_calculated\n",
        "\n",
        "    def evaluate(self,x_test,y_test):\n",
        "        accuracy = evaluate_predictions(x_test,y_test,self.mean0,self.std0,self.mean1,self.std1)\n",
        "        return accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "u1_JsfHyJ_wZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    my_classifier = NaiveBayesClassifier()\n",
        "    my_classifier.fit(x_train,y_train)\n",
        "    accuracy = my_classifier.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "fipNBcpvKDss"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UufLQU0bKO4W",
        "outputId": "39bbe867-3dff-4867-a978-eb83f0179c3c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7395833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets compare the acuracy obtained runing the Naive Bayes methods available in sklearn library.\n",
        "It was loaded before in from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "bUb3ePbbCMJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets try it from sklearn\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "9YUy4_YiZRo_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(x_train, y_train).predict(x_test)"
      ],
      "metadata": {
        "id": "X0otgo6QaHyO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1behUgUEaKDc",
        "outputId": "a70386a9-0417-46fc-d1cb-b997863deb34"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7395833333333334"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! We obtained the same result! In just three lines, we achieved the same accuracy as the one obtained using the Classifier From Scratch."
      ],
      "metadata": {
        "id": "1tm0thSyDHnl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ehLLpYJa3CF"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}